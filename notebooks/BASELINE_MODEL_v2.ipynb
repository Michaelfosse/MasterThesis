{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r\"references\\Subject_info.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Research Group</th>\n",
       "      <th>APOE A1</th>\n",
       "      <th>APOE A2</th>\n",
       "      <th>Age</th>\n",
       "      <th>dataset_split</th>\n",
       "      <th>File_Path</th>\n",
       "      <th>File_Path_desktop</th>\n",
       "      <th>PATH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002_S_0295</td>\n",
       "      <td>M</td>\n",
       "      <td>73.0</td>\n",
       "      <td>CN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>train</td>\n",
       "      <td>C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...</td>\n",
       "      <td>D:\\Data\\Preprocessed\\Fused Images\\002_S_0295_f...</td>\n",
       "      <td>data\\processed\\002_S_0295_fused.nii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002_S_0413</td>\n",
       "      <td>F</td>\n",
       "      <td>57.6</td>\n",
       "      <td>CN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>81.5</td>\n",
       "      <td>test</td>\n",
       "      <td>C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...</td>\n",
       "      <td>D:\\Data\\Preprocessed\\Fused Images\\002_S_0413_f...</td>\n",
       "      <td>data\\processed\\002_S_0413_fused.nii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002_S_0685</td>\n",
       "      <td>F</td>\n",
       "      <td>68.9</td>\n",
       "      <td>CN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>95.8</td>\n",
       "      <td>test</td>\n",
       "      <td>C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...</td>\n",
       "      <td>D:\\Data\\Preprocessed\\Fused Images\\002_S_0685_f...</td>\n",
       "      <td>data\\processed\\002_S_0685_fused.nii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002_S_0729</td>\n",
       "      <td>F</td>\n",
       "      <td>65.8</td>\n",
       "      <td>MCI</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>71.3</td>\n",
       "      <td>validation</td>\n",
       "      <td>C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...</td>\n",
       "      <td>D:\\Data\\Preprocessed\\Fused Images\\002_S_0729_f...</td>\n",
       "      <td>data\\processed\\002_S_0729_fused.nii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002_S_1155</td>\n",
       "      <td>M</td>\n",
       "      <td>64.9</td>\n",
       "      <td>MCI</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>train</td>\n",
       "      <td>C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...</td>\n",
       "      <td>D:\\Data\\Preprocessed\\Fused Images\\002_S_1155_f...</td>\n",
       "      <td>data\\processed\\002_S_1155_fused.nii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>941_S_4377</td>\n",
       "      <td>F</td>\n",
       "      <td>121.6</td>\n",
       "      <td>MCI</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>69.5</td>\n",
       "      <td>test</td>\n",
       "      <td>C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...</td>\n",
       "      <td>D:\\Data\\Preprocessed\\Fused Images\\941_S_4377_f...</td>\n",
       "      <td>data\\processed\\941_S_4377_fused.nii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>941_S_4420</td>\n",
       "      <td>M</td>\n",
       "      <td>79.4</td>\n",
       "      <td>MCI</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>81.5</td>\n",
       "      <td>train</td>\n",
       "      <td>C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...</td>\n",
       "      <td>D:\\Data\\Preprocessed\\Fused Images\\941_S_4420_f...</td>\n",
       "      <td>data\\processed\\941_S_4420_fused.nii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>941_S_4764</td>\n",
       "      <td>F</td>\n",
       "      <td>77.6</td>\n",
       "      <td>MCI</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>82.8</td>\n",
       "      <td>train</td>\n",
       "      <td>C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...</td>\n",
       "      <td>D:\\Data\\Preprocessed\\Fused Images\\941_S_4764_f...</td>\n",
       "      <td>data\\processed\\941_S_4764_fused.nii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>941_S_5124</td>\n",
       "      <td>F</td>\n",
       "      <td>78.9</td>\n",
       "      <td>CN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>76.8</td>\n",
       "      <td>test</td>\n",
       "      <td>C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...</td>\n",
       "      <td>D:\\Data\\Preprocessed\\Fused Images\\941_S_5124_f...</td>\n",
       "      <td>data\\processed\\941_S_5124_fused.nii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>941_S_5193</td>\n",
       "      <td>F</td>\n",
       "      <td>88.9</td>\n",
       "      <td>CN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>72.6</td>\n",
       "      <td>train</td>\n",
       "      <td>C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...</td>\n",
       "      <td>D:\\Data\\Preprocessed\\Fused Images\\941_S_5193_f...</td>\n",
       "      <td>data\\processed\\941_S_5193_fused.nii</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Subject Sex  Weight Research Group  APOE A1  APOE A2   Age  \\\n",
       "0    002_S_0295   M    73.0             CN      3.0      4.0  90.0   \n",
       "1    002_S_0413   F    57.6             CN      3.0      3.0  81.5   \n",
       "2    002_S_0685   F    68.9             CN      3.0      3.0  95.8   \n",
       "3    002_S_0729   F    65.8            MCI      3.0      4.0  71.3   \n",
       "4    002_S_1155   M    64.9            MCI      3.0      3.0  64.0   \n",
       "..          ...  ..     ...            ...      ...      ...   ...   \n",
       "173  941_S_4377   F   121.6            MCI      3.0      4.0  69.5   \n",
       "174  941_S_4420   M    79.4            MCI      3.0      3.0  81.5   \n",
       "175  941_S_4764   F    77.6            MCI      3.0      3.0  82.8   \n",
       "176  941_S_5124   F    78.9             CN      3.0      3.0  76.8   \n",
       "177  941_S_5193   F    88.9             CN      3.0      3.0  72.6   \n",
       "\n",
       "    dataset_split                                          File_Path  \\\n",
       "0           train  C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...   \n",
       "1            test  C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...   \n",
       "2            test  C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...   \n",
       "3      validation  C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...   \n",
       "4           train  C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...   \n",
       "..            ...                                                ...   \n",
       "173          test  C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...   \n",
       "174         train  C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...   \n",
       "175         train  C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...   \n",
       "176          test  C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...   \n",
       "177         train  C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...   \n",
       "\n",
       "                                     File_Path_desktop  \\\n",
       "0    D:\\Data\\Preprocessed\\Fused Images\\002_S_0295_f...   \n",
       "1    D:\\Data\\Preprocessed\\Fused Images\\002_S_0413_f...   \n",
       "2    D:\\Data\\Preprocessed\\Fused Images\\002_S_0685_f...   \n",
       "3    D:\\Data\\Preprocessed\\Fused Images\\002_S_0729_f...   \n",
       "4    D:\\Data\\Preprocessed\\Fused Images\\002_S_1155_f...   \n",
       "..                                                 ...   \n",
       "173  D:\\Data\\Preprocessed\\Fused Images\\941_S_4377_f...   \n",
       "174  D:\\Data\\Preprocessed\\Fused Images\\941_S_4420_f...   \n",
       "175  D:\\Data\\Preprocessed\\Fused Images\\941_S_4764_f...   \n",
       "176  D:\\Data\\Preprocessed\\Fused Images\\941_S_5124_f...   \n",
       "177  D:\\Data\\Preprocessed\\Fused Images\\941_S_5193_f...   \n",
       "\n",
       "                                    PATH  \n",
       "0    data\\processed\\002_S_0295_fused.nii  \n",
       "1    data\\processed\\002_S_0413_fused.nii  \n",
       "2    data\\processed\\002_S_0685_fused.nii  \n",
       "3    data\\processed\\002_S_0729_fused.nii  \n",
       "4    data\\processed\\002_S_1155_fused.nii  \n",
       "..                                   ...  \n",
       "173  data\\processed\\941_S_4377_fused.nii  \n",
       "174  data\\processed\\941_S_4420_fused.nii  \n",
       "175  data\\processed\\941_S_4764_fused.nii  \n",
       "176  data\\processed\\941_S_5124_fused.nii  \n",
       "177  data\\processed\\941_S_5193_fused.nii  \n",
       "\n",
       "[178 rows x 11 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming df is your DataFrame\n",
    "def preprocess_labels(df):\n",
    "    # Mapping similar categories to a single category\n",
    "    label_mapping = {\n",
    "        'EMCI': 'MCI',\n",
    "        'LMCI': 'MCI',\n",
    "        'SMC': 'CN'  # If you want SMC to be considered as CN, include this; remove if not\n",
    "    }\n",
    "    df['Research Group'] = df['Research Group'].replace(label_mapping)\n",
    "    return df\n",
    "\n",
    "preprocess_labels(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "df = df[df['Research Group'] != 'AD']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 167 entries, 0 to 177\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Subject            167 non-null    object \n",
      " 1   Sex                167 non-null    object \n",
      " 2   Weight             167 non-null    float64\n",
      " 3   Research Group     167 non-null    object \n",
      " 4   APOE A1            165 non-null    float64\n",
      " 5   APOE A2            165 non-null    float64\n",
      " 6   Age                167 non-null    float64\n",
      " 7   dataset_split      167 non-null    object \n",
      " 8   File_Path          167 non-null    object \n",
      " 9   File_Path_desktop  167 non-null    object \n",
      " 10  PATH               167 non-null    object \n",
      "dtypes: float64(4), object(7)\n",
      "memory usage: 15.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Research Group</th>\n",
       "      <th>APOE A1</th>\n",
       "      <th>APOE A2</th>\n",
       "      <th>Age</th>\n",
       "      <th>dataset_split</th>\n",
       "      <th>File_Path</th>\n",
       "      <th>File_Path_desktop</th>\n",
       "      <th>PATH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002_S_0295</td>\n",
       "      <td>M</td>\n",
       "      <td>73.0</td>\n",
       "      <td>CN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>train</td>\n",
       "      <td>C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...</td>\n",
       "      <td>D:\\Data\\Preprocessed\\Fused Images\\002_S_0295_f...</td>\n",
       "      <td>data\\processed\\002_S_0295_fused.nii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002_S_0413</td>\n",
       "      <td>F</td>\n",
       "      <td>57.6</td>\n",
       "      <td>CN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>81.5</td>\n",
       "      <td>test</td>\n",
       "      <td>C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...</td>\n",
       "      <td>D:\\Data\\Preprocessed\\Fused Images\\002_S_0413_f...</td>\n",
       "      <td>data\\processed\\002_S_0413_fused.nii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002_S_0685</td>\n",
       "      <td>F</td>\n",
       "      <td>68.9</td>\n",
       "      <td>CN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>95.8</td>\n",
       "      <td>test</td>\n",
       "      <td>C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...</td>\n",
       "      <td>D:\\Data\\Preprocessed\\Fused Images\\002_S_0685_f...</td>\n",
       "      <td>data\\processed\\002_S_0685_fused.nii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002_S_0729</td>\n",
       "      <td>F</td>\n",
       "      <td>65.8</td>\n",
       "      <td>MCI</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>71.3</td>\n",
       "      <td>validation</td>\n",
       "      <td>C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...</td>\n",
       "      <td>D:\\Data\\Preprocessed\\Fused Images\\002_S_0729_f...</td>\n",
       "      <td>data\\processed\\002_S_0729_fused.nii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002_S_1155</td>\n",
       "      <td>M</td>\n",
       "      <td>64.9</td>\n",
       "      <td>MCI</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>train</td>\n",
       "      <td>C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...</td>\n",
       "      <td>D:\\Data\\Preprocessed\\Fused Images\\002_S_1155_f...</td>\n",
       "      <td>data\\processed\\002_S_1155_fused.nii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>941_S_4377</td>\n",
       "      <td>F</td>\n",
       "      <td>121.6</td>\n",
       "      <td>MCI</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>69.5</td>\n",
       "      <td>test</td>\n",
       "      <td>C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...</td>\n",
       "      <td>D:\\Data\\Preprocessed\\Fused Images\\941_S_4377_f...</td>\n",
       "      <td>data\\processed\\941_S_4377_fused.nii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>941_S_4420</td>\n",
       "      <td>M</td>\n",
       "      <td>79.4</td>\n",
       "      <td>MCI</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>81.5</td>\n",
       "      <td>train</td>\n",
       "      <td>C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...</td>\n",
       "      <td>D:\\Data\\Preprocessed\\Fused Images\\941_S_4420_f...</td>\n",
       "      <td>data\\processed\\941_S_4420_fused.nii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>941_S_4764</td>\n",
       "      <td>F</td>\n",
       "      <td>77.6</td>\n",
       "      <td>MCI</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>82.8</td>\n",
       "      <td>train</td>\n",
       "      <td>C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...</td>\n",
       "      <td>D:\\Data\\Preprocessed\\Fused Images\\941_S_4764_f...</td>\n",
       "      <td>data\\processed\\941_S_4764_fused.nii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>941_S_5124</td>\n",
       "      <td>F</td>\n",
       "      <td>78.9</td>\n",
       "      <td>CN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>76.8</td>\n",
       "      <td>test</td>\n",
       "      <td>C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...</td>\n",
       "      <td>D:\\Data\\Preprocessed\\Fused Images\\941_S_5124_f...</td>\n",
       "      <td>data\\processed\\941_S_5124_fused.nii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>941_S_5193</td>\n",
       "      <td>F</td>\n",
       "      <td>88.9</td>\n",
       "      <td>CN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>72.6</td>\n",
       "      <td>train</td>\n",
       "      <td>C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...</td>\n",
       "      <td>D:\\Data\\Preprocessed\\Fused Images\\941_S_5193_f...</td>\n",
       "      <td>data\\processed\\941_S_5193_fused.nii</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Subject Sex  Weight Research Group  APOE A1  APOE A2   Age  \\\n",
       "0    002_S_0295   M    73.0             CN      3.0      4.0  90.0   \n",
       "1    002_S_0413   F    57.6             CN      3.0      3.0  81.5   \n",
       "2    002_S_0685   F    68.9             CN      3.0      3.0  95.8   \n",
       "3    002_S_0729   F    65.8            MCI      3.0      4.0  71.3   \n",
       "4    002_S_1155   M    64.9            MCI      3.0      3.0  64.0   \n",
       "..          ...  ..     ...            ...      ...      ...   ...   \n",
       "173  941_S_4377   F   121.6            MCI      3.0      4.0  69.5   \n",
       "174  941_S_4420   M    79.4            MCI      3.0      3.0  81.5   \n",
       "175  941_S_4764   F    77.6            MCI      3.0      3.0  82.8   \n",
       "176  941_S_5124   F    78.9             CN      3.0      3.0  76.8   \n",
       "177  941_S_5193   F    88.9             CN      3.0      3.0  72.6   \n",
       "\n",
       "    dataset_split                                          File_Path  \\\n",
       "0           train  C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...   \n",
       "1            test  C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...   \n",
       "2            test  C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...   \n",
       "3      validation  C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...   \n",
       "4           train  C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...   \n",
       "..            ...                                                ...   \n",
       "173          test  C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...   \n",
       "174         train  C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...   \n",
       "175         train  C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...   \n",
       "176          test  C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...   \n",
       "177         train  C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...   \n",
       "\n",
       "                                     File_Path_desktop  \\\n",
       "0    D:\\Data\\Preprocessed\\Fused Images\\002_S_0295_f...   \n",
       "1    D:\\Data\\Preprocessed\\Fused Images\\002_S_0413_f...   \n",
       "2    D:\\Data\\Preprocessed\\Fused Images\\002_S_0685_f...   \n",
       "3    D:\\Data\\Preprocessed\\Fused Images\\002_S_0729_f...   \n",
       "4    D:\\Data\\Preprocessed\\Fused Images\\002_S_1155_f...   \n",
       "..                                                 ...   \n",
       "173  D:\\Data\\Preprocessed\\Fused Images\\941_S_4377_f...   \n",
       "174  D:\\Data\\Preprocessed\\Fused Images\\941_S_4420_f...   \n",
       "175  D:\\Data\\Preprocessed\\Fused Images\\941_S_4764_f...   \n",
       "176  D:\\Data\\Preprocessed\\Fused Images\\941_S_5124_f...   \n",
       "177  D:\\Data\\Preprocessed\\Fused Images\\941_S_5193_f...   \n",
       "\n",
       "                                    PATH  \n",
       "0    data\\processed\\002_S_0295_fused.nii  \n",
       "1    data\\processed\\002_S_0413_fused.nii  \n",
       "2    data\\processed\\002_S_0685_fused.nii  \n",
       "3    data\\processed\\002_S_0729_fused.nii  \n",
       "4    data\\processed\\002_S_1155_fused.nii  \n",
       "..                                   ...  \n",
       "173  data\\processed\\941_S_4377_fused.nii  \n",
       "174  data\\processed\\941_S_4420_fused.nii  \n",
       "175  data\\processed\\941_S_4764_fused.nii  \n",
       "176  data\\processed\\941_S_5124_fused.nii  \n",
       "177  data\\processed\\941_S_5193_fused.nii  \n",
       "\n",
       "[167 rows x 11 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NiiDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        \"\"\"\n",
    "        Initializes the dataset object.\n",
    "        :param df: DataFrame containing file paths, labels, and subject IDs.\n",
    "        :param transform: A function or a series of transforms to apply to the images.\n",
    "        \"\"\"\n",
    "        self.paths = df['PATH'].tolist()  # Paths to .nii files\n",
    "        # Convert labels to categorical codes and maintain a mapping\n",
    "        self.label_mapping = {category: code for code, category in enumerate(pd.Categorical(df['Research Group']).categories)}\n",
    "        self.labels = pd.Categorical(df['Research Group'], categories=self.label_mapping.keys()).codes\n",
    "        self.subjects = df['Subject'].tolist()  # Subject identifiers\n",
    "        self.transform = transform  # Transformation function(s)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the total number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        try:\n",
    "            image = nib.load(path).get_fdata()\n",
    "            image = np.expand_dims(image, axis=0)  # Add a channel dimension\n",
    "            image = image.astype(np.float32)  # Ensure the image is float32\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading NII file at {path}: {e}\")\n",
    "            image = np.zeros((1, 64, 64, 64), dtype=np.float32)  # Fallback image of the same type\n",
    "\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        subject = self.subjects[idx]\n",
    "\n",
    "        return image, label, path, subject\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "def load_datasets(df):\n",
    "    train_df = df[df['dataset_split'] == 'train']\n",
    "    val_df = df[df['dataset_split'] == 'validation']\n",
    "    test_df = df[df['dataset_split'] == 'test']\n",
    "    \n",
    "    train_dataset = NiiDataset(train_df)\n",
    "    val_dataset = NiiDataset(val_df)\n",
    "    test_dataset = NiiDataset(test_df)\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(train_dataset, val_dataset, test_dataset, batch_size=4):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "class Baseline3DCNN(nn.Module):\n",
    "    def __init__(self, num_classes=3, init_filters=32, kernel_size=3, stride=2, num_fc_units=128):\n",
    "        super(Baseline3DCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(1, init_filters, kernel_size=kernel_size, stride=stride, padding=1)\n",
    "        self.conv2 = nn.Conv3d(init_filters, init_filters*2, kernel_size=kernel_size, stride=stride, padding=1)\n",
    "        self.conv3 = nn.Conv3d(init_filters*2, init_filters*4, kernel_size=kernel_size, stride=stride, padding=1)\n",
    "        self.pool = nn.MaxPool3d(2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Compute the flattened size after all convolutions and pooling\n",
    "        self.final_dim = self._get_conv_output_dim(193, 3, stride, kernel_size, init_filters*4)\n",
    "        self.fc1 = nn.Linear(self.final_dim, num_fc_units)\n",
    "        self.fc2 = nn.Linear(num_fc_units, num_classes)\n",
    "\n",
    "    def _get_conv_output_dim(self, input_dim, num_convs, stride, kernel_size, num_filters):\n",
    "        output_dim = input_dim\n",
    "        for _ in range(num_convs):\n",
    "            output_dim = ((output_dim - kernel_size + 2 * (kernel_size // 2)) // stride + 1) // 2  # Pooling divides size by 2\n",
    "        return output_dim * output_dim * output_dim * num_filters\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available and set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df' is your DataFrame loaded with the 'Research Group' column available\n",
    "label_categories = pd.Categorical(df['Research Group'])\n",
    "label_mapping = {code: category for code, category in enumerate(label_categories.categories)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, label_mapping, num_epochs=10, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    train_results = []\n",
    "    for epoch in range(num_epochs):\n",
    "        for images, labels, paths, subjects in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted_indices = torch.max(outputs, 1)\n",
    "            predicted_labels = [label_mapping[code] for code in predicted_indices.cpu().numpy()]\n",
    "\n",
    "            for label, pred, path, subject in zip(labels.cpu().numpy(), predicted_labels, paths, subjects):\n",
    "                train_results.append({\n",
    "                    'Subject': subject,\n",
    "                    'Path': path,\n",
    "                    'Actual Label': label_mapping[label.item()],\n",
    "                    'Prediction': pred,\n",
    "                    'Type': 'Train'\n",
    "                })\n",
    "    return train_results\n",
    "\n",
    "def validate_model(model, val_loader, criterion, label_mapping, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    validation_results = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels, paths, subjects in tqdm(val_loader, desc='Validation'):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted_indices = torch.max(outputs, 1)\n",
    "            predicted_labels = [label_mapping[code] for code in predicted_indices.cpu().numpy()]\n",
    "\n",
    "            for label, pred, path, subject in zip(labels.cpu().numpy(), predicted_labels, paths, subjects):\n",
    "                validation_results.append({\n",
    "                    'Subject': subject,\n",
    "                    'Path': path,\n",
    "                    'Actual Label': label_mapping[label.item()],\n",
    "                    'Prediction': pred,\n",
    "                    'Type': 'Validation'\n",
    "                })\n",
    "    return validation_results\n",
    "\n",
    "def test_model(model, test_loader, label_mapping, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    test_results = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels, paths, subjects in tqdm(test_loader, desc='Testing'):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted_indices = torch.max(outputs, 1)\n",
    "            predicted_labels = [label_mapping[code] for code in predicted_indices.cpu().numpy()]\n",
    "\n",
    "            for label, pred, path, subject in zip(labels.cpu().numpy(), predicted_labels, paths, subjects):\n",
    "                test_results.append({\n",
    "                    'Subject': subject,\n",
    "                    'Path': path,\n",
    "                    'Actual Label': label_mapping[label.item()],\n",
    "                    'Prediction': pred,\n",
    "                    'Type': 'Test'\n",
    "                })\n",
    "    return test_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = load_datasets(df)  # Create datasets\n",
    "train_loader, val_loader, test_loader = create_dataloaders(train_dataset, val_dataset, test_dataset, batch_size=4)  # Create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  32%|███▏      | 8/25 [00:20<00:42,  2.49s/it]"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "config = {\n",
    "    'num_classes': 3,\n",
    "    'init_filters': 32,\n",
    "    'kernel_size': 3,\n",
    "    'stride': 2,\n",
    "    'num_fc_units': 128,\n",
    "    'optimizer': 'Adam',\n",
    "    'loss_criterion': 'CrossEntropyLoss',\n",
    "    'num_epochs': 10\n",
    "}\n",
    "config_df = pd.DataFrame([config])\n",
    "\n",
    "# Model Initialization\n",
    "model = Baseline3DCNN(num_classes=config['num_classes'],\n",
    "                      init_filters=config['init_filters'],\n",
    "                      kernel_size=config['kernel_size'],\n",
    "                      stride=config['stride'],\n",
    "                      num_fc_units=config['num_fc_units']).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Prepare DataLoaders (assuming your datasets are already split and loaded into variables train_dataset, val_dataset, test_dataset)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "# Training, Validation, Testing\n",
    "train_results = train_model(model, train_loader, criterion, optimizer, label_mapping, num_epochs=config['num_epochs'], device=device)\n",
    "validate_results = validate_model(model, val_loader, criterion, label_mapping, device=device)\n",
    "test_results = test_model(model, test_loader, label_mapping, device=device)\n",
    "\n",
    "# Combine results from all phases\n",
    "all_results = pd.DataFrame(train_results + validate_results + test_results)\n",
    "\n",
    "import datetime\n",
    "\n",
    "# Assuming config_df and all_results are defined elsewhere in your script\n",
    "# Get the current date and time\n",
    "current_time = datetime.datetime.now()\n",
    "formatted_time = current_time.strftime('%Y-%m-%d_%H-%M-%S')  # Format as Year-Month-Day_Hour-Minute-Second\n",
    "\n",
    "# Create a unique filename for each experiment run\n",
    "filename = f'{formatted_time}_Experiment.xlsx'\n",
    "\n",
    "# Export to Excel with a unique filename based on the current date and time\n",
    "with pd.ExcelWriter(filename) as writer:\n",
    "    config_df.to_excel(writer, sheet_name='Configuration')\n",
    "    all_results.to_excel(writer, sheet_name='Results')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 2\u001b[0m     image \u001b[38;5;241m=\u001b[39m nib\u001b[38;5;241m.\u001b[39mload(\u001b[43mpath\u001b[49m)\u001b[38;5;241m.\u001b[39mget_fdata()  \u001b[38;5;66;03m# Load the image data\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'path' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m     image \u001b[38;5;241m=\u001b[39m nib\u001b[38;5;241m.\u001b[39mload(path)\u001b[38;5;241m.\u001b[39mget_fdata()  \u001b[38;5;66;03m# Load the image data\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError loading NII file at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Handle the error, e.g., by skipping this file or using a default image\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'path' is not defined"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    image = nib.load(path).get_fdata()  # Load the image data\n",
    "except Exception as e:\n",
    "    print(f\"Error loading NII file at {path}: {e}\")\n",
    "    # Handle the error, e.g., by skipping this file or using a default image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
