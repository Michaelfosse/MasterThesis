{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Micha\\\\Github Repo'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r\"C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania\\MsC Business Analytics\\Master Thesis\\Python\\Subject_info.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178 entries, 0 to 177\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Subject            178 non-null    object \n",
      " 1   Sex                178 non-null    object \n",
      " 2   Weight             178 non-null    float64\n",
      " 3   Research Group     178 non-null    object \n",
      " 4   APOE A1            176 non-null    float64\n",
      " 5   APOE A2            176 non-null    float64\n",
      " 6   Age                178 non-null    float64\n",
      " 7   dataset_split      178 non-null    object \n",
      " 8   File_Path          178 non-null    object \n",
      " 9   File_Path_desktop  178 non-null    object \n",
      "dtypes: float64(4), object(6)\n",
      "memory usage: 14.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Baseline3DCNN().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize, train, validate, and test the model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m Baseline3DCNN(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 3\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m train_model(model, \u001b[43mtrain_loader\u001b[49m, criterion, optimizer, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m      4\u001b[0m val_accuracy \u001b[38;5;241m=\u001b[39m validate_model(model, val_loader, criterion)\n\u001b[0;32m      5\u001b[0m test_accuracy \u001b[38;5;241m=\u001b[39m test_model(model, test_loader)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize, train, validate, and test the model\n",
    "model = Baseline3DCNN(**params).to(device)\n",
    "train_loss = train_model(model, train_loader, criterion, optimizer, num_epochs=10)\n",
    "val_accuracy = validate_model(model, val_loader, criterion)\n",
    "test_accuracy = test_model(model, test_loader)\n",
    "\n",
    "# Log the experiment\n",
    "log_experiment(params, train_loss, val_accuracy, test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(r\"C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania\\MsC Business Analytics\\Master Thesis\\Python\\Subject_info.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Research Group</th>\n",
       "      <th>APOE A1</th>\n",
       "      <th>APOE A2</th>\n",
       "      <th>Age</th>\n",
       "      <th>dataset_split</th>\n",
       "      <th>File_Path</th>\n",
       "      <th>File_Path_desktop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002_S_0295</td>\n",
       "      <td>M</td>\n",
       "      <td>73.0</td>\n",
       "      <td>CN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>train</td>\n",
       "      <td>C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...</td>\n",
       "      <td>D:\\Data\\Preprocessed\\Fused Images\\002_S_0295_f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002_S_0413</td>\n",
       "      <td>F</td>\n",
       "      <td>57.6</td>\n",
       "      <td>CN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>81.5</td>\n",
       "      <td>test</td>\n",
       "      <td>C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...</td>\n",
       "      <td>D:\\Data\\Preprocessed\\Fused Images\\002_S_0413_f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002_S_0685</td>\n",
       "      <td>F</td>\n",
       "      <td>68.9</td>\n",
       "      <td>CN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>95.8</td>\n",
       "      <td>test</td>\n",
       "      <td>C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...</td>\n",
       "      <td>D:\\Data\\Preprocessed\\Fused Images\\002_S_0685_f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002_S_0729</td>\n",
       "      <td>F</td>\n",
       "      <td>65.8</td>\n",
       "      <td>MCI</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>71.3</td>\n",
       "      <td>validation</td>\n",
       "      <td>C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...</td>\n",
       "      <td>D:\\Data\\Preprocessed\\Fused Images\\002_S_0729_f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>002_S_1155</td>\n",
       "      <td>M</td>\n",
       "      <td>64.9</td>\n",
       "      <td>MCI</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>train</td>\n",
       "      <td>C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...</td>\n",
       "      <td>D:\\Data\\Preprocessed\\Fused Images\\002_S_1155_f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>941_S_4377</td>\n",
       "      <td>F</td>\n",
       "      <td>121.6</td>\n",
       "      <td>MCI</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>69.5</td>\n",
       "      <td>test</td>\n",
       "      <td>C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...</td>\n",
       "      <td>D:\\Data\\Preprocessed\\Fused Images\\941_S_4377_f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>941_S_4420</td>\n",
       "      <td>M</td>\n",
       "      <td>79.4</td>\n",
       "      <td>MCI</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>81.5</td>\n",
       "      <td>train</td>\n",
       "      <td>C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...</td>\n",
       "      <td>D:\\Data\\Preprocessed\\Fused Images\\941_S_4420_f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>941_S_4764</td>\n",
       "      <td>F</td>\n",
       "      <td>77.6</td>\n",
       "      <td>MCI</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>82.8</td>\n",
       "      <td>train</td>\n",
       "      <td>C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...</td>\n",
       "      <td>D:\\Data\\Preprocessed\\Fused Images\\941_S_4764_f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>941_S_5124</td>\n",
       "      <td>F</td>\n",
       "      <td>78.9</td>\n",
       "      <td>CN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>76.8</td>\n",
       "      <td>test</td>\n",
       "      <td>C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...</td>\n",
       "      <td>D:\\Data\\Preprocessed\\Fused Images\\941_S_5124_f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>941_S_5193</td>\n",
       "      <td>F</td>\n",
       "      <td>88.9</td>\n",
       "      <td>CN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>72.6</td>\n",
       "      <td>train</td>\n",
       "      <td>C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...</td>\n",
       "      <td>D:\\Data\\Preprocessed\\Fused Images\\941_S_5193_f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Subject Sex  Weight Research Group  APOE A1  APOE A2   Age  \\\n",
       "0    002_S_0295   M    73.0             CN      3.0      4.0  90.0   \n",
       "1    002_S_0413   F    57.6             CN      3.0      3.0  81.5   \n",
       "2    002_S_0685   F    68.9             CN      3.0      3.0  95.8   \n",
       "3    002_S_0729   F    65.8            MCI      3.0      4.0  71.3   \n",
       "4    002_S_1155   M    64.9            MCI      3.0      3.0  64.0   \n",
       "..          ...  ..     ...            ...      ...      ...   ...   \n",
       "173  941_S_4377   F   121.6            MCI      3.0      4.0  69.5   \n",
       "174  941_S_4420   M    79.4            MCI      3.0      3.0  81.5   \n",
       "175  941_S_4764   F    77.6            MCI      3.0      3.0  82.8   \n",
       "176  941_S_5124   F    78.9             CN      3.0      3.0  76.8   \n",
       "177  941_S_5193   F    88.9             CN      3.0      3.0  72.6   \n",
       "\n",
       "    dataset_split                                          File_Path  \\\n",
       "0           train  C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...   \n",
       "1            test  C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...   \n",
       "2            test  C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...   \n",
       "3      validation  C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...   \n",
       "4           train  C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...   \n",
       "..            ...                                                ...   \n",
       "173          test  C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...   \n",
       "174         train  C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...   \n",
       "175         train  C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...   \n",
       "176          test  C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...   \n",
       "177         train  C:\\Users\\Micha\\OneDrive - Høyskolen Kristiania...   \n",
       "\n",
       "                                     File_Path_desktop  \n",
       "0    D:\\Data\\Preprocessed\\Fused Images\\002_S_0295_f...  \n",
       "1    D:\\Data\\Preprocessed\\Fused Images\\002_S_0413_f...  \n",
       "2    D:\\Data\\Preprocessed\\Fused Images\\002_S_0685_f...  \n",
       "3    D:\\Data\\Preprocessed\\Fused Images\\002_S_0729_f...  \n",
       "4    D:\\Data\\Preprocessed\\Fused Images\\002_S_1155_f...  \n",
       "..                                                 ...  \n",
       "173  D:\\Data\\Preprocessed\\Fused Images\\941_S_4377_f...  \n",
       "174  D:\\Data\\Preprocessed\\Fused Images\\941_S_4420_f...  \n",
       "175  D:\\Data\\Preprocessed\\Fused Images\\941_S_4764_f...  \n",
       "176  D:\\Data\\Preprocessed\\Fused Images\\941_S_5124_f...  \n",
       "177  D:\\Data\\Preprocessed\\Fused Images\\941_S_5193_f...  \n",
       "\n",
       "[178 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming df is your DataFrame\n",
    "def preprocess_labels(df):\n",
    "    # Mapping similar categories to a single category\n",
    "    label_mapping = {\n",
    "        'EMCI': 'MCI',\n",
    "        'LMCI': 'MCI',\n",
    "        'SMC': 'CN'  # If you want SMC to be considered as CN, include this; remove if not\n",
    "    }\n",
    "    df['Research Group'] = df['Research Group'].replace(label_mapping)\n",
    "    return df\n",
    "\n",
    "preprocess_labels(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NiiDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.paths = df['File_Path_desktop'].tolist()\n",
    "        self.labels = pd.Categorical(df['Research Group']).codes\n",
    "        self.subjects = df['Subject'].tolist()  # Assuming 'Subject' is the column name for subject identifiers\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        image = nib.load(path).get_fdata()\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        subject = self.subjects[idx]  # Get the subject identifier\n",
    "        \n",
    "        return image, label, path, subject\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_datasets(df):\n",
    "    # Define custom transform functions here\n",
    "    def custom_transform(image):\n",
    "        # Convert to tensor\n",
    "        tensor_image = torch.from_numpy(image).float()\n",
    "        # Normalize\n",
    "        tensor_image = (tensor_image - tensor_image.min()) / (tensor_image.max() - tensor_image.min()) * (1.0 - 0.0) + 0.0\n",
    "        return tensor_image\n",
    "    \n",
    "\n",
    "    transform = custom_transform\n",
    "    \n",
    "    train_df = df[df['dataset_split'] == 'train']\n",
    "    val_df = df[df['dataset_split'] == 'validation']\n",
    "    test_df = df[df['dataset_split'] == 'test']\n",
    "    \n",
    "    train_dataset = NiiDataset(train_df, transform=transform)\n",
    "    val_dataset = NiiDataset(val_df, transform=transform)\n",
    "    test_dataset = NiiDataset(test_df, transform=transform)\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(train_dataset, val_dataset, test_dataset, batch_size=4):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model definition\n",
    "class Baseline3DCNN(nn.Module):\n",
    "    def __init__(self, num_classes=3, init_filters=32, kernel_size=3, stride=2, num_fc_units=128):\n",
    "        super(Baseline3DCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(1, init_filters, kernel_size=kernel_size, stride=stride, padding=1)\n",
    "        self.conv2 = nn.Conv3d(init_filters, init_filters*2, kernel_size=kernel_size, stride=stride, padding=1)\n",
    "        self.conv3 = nn.Conv3d(init_filters*2, init_filters*4, kernel_size=kernel_size, stride=stride, padding=1)\n",
    "        self.pool = nn.MaxPool3d(2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Compute the flattened size after all convolutions and pooling\n",
    "        self.final_dim = self._get_conv_output_dim(193, 3, stride, kernel_size, init_filters*4)\n",
    "        self.fc1 = nn.Linear(self.final_dim, num_fc_units)\n",
    "        self.fc2 = nn.Linear(num_fc_units, num_classes)\n",
    "\n",
    "    def _get_conv_output_dim(self, input_dim, num_convs, stride, kernel_size, num_filters):\n",
    "        output_dim = input_dim\n",
    "        for _ in range(num_convs):\n",
    "            output_dim = ((output_dim - kernel_size + 2 * (kernel_size // 2)) // stride + 1) // 2  # Pooling divides size by 2\n",
    "        return output_dim * output_dim * output_dim * num_filters\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available and set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping of label codes to label names\n",
    "unique_labels = pd.Categorical(df['Research Group'])\n",
    "label_mapping = {code: name for code, name in zip(unique_labels.codes, unique_labels.categories)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10, device='cpu'):\n",
    "    model.to(device)  # Move the model to the appropriate device\n",
    "    model.train()\n",
    "    train_results = []\n",
    "    for epoch in range(num_epochs):\n",
    "        for images, labels, paths, subjects in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted_indices = torch.max(outputs.data, 1)\n",
    "            \n",
    "            # Debugging code to inspect predicted indices\n",
    "            print(\"Predicted Indices:\", predicted_indices.cpu().numpy())\n",
    "            \n",
    "            # Check for any predicted indices not present in label_mapping\n",
    "            for code in predicted_indices.cpu().numpy():\n",
    "                if code not in label_mapping:\n",
    "                    print(f\"Predicted index {code} not found in label_mapping!\")\n",
    "            \n",
    "            # Original code to retrieve predicted labels\n",
    "            predicted_labels = [label_mapping[code] for code in predicted_indices.cpu().numpy()]\n",
    "            \n",
    "            # Continue with original code\n",
    "            for label, pred, path, subject in zip(labels.cpu().numpy(), predicted_labels, paths, subjects):\n",
    "                train_results.append({\n",
    "                    'Subject': subject,\n",
    "                    'Path': path,\n",
    "                    'Actual Label': label_mapping[label.item()],  # Now using label_mapping to get actual label name\n",
    "                    'Prediction': pred,\n",
    "                    'Type': 'Train'\n",
    "                })\n",
    "    return train_results\n",
    "\n",
    "def validate_model(model, val_loader, criterion, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    validation_results = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels, paths, subjects in tqdm(val_loader, desc='Validation'):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted_indices = torch.max(outputs.data, 1)\n",
    "            predicted_labels = [label_mapping[code] for code in predicted_indices.cpu().numpy()]\n",
    "            for label, pred, path, subject in zip(labels.cpu().numpy(), predicted_labels, paths, subjects):\n",
    "                validation_results.append({\n",
    "                    'Subject': subject,\n",
    "                    'Path': path,\n",
    "                    'Actual Label': label_mapping[label.item()],\n",
    "                    'Prediction': pred,\n",
    "                    'Type': 'Validation'\n",
    "                })\n",
    "    return validation_results\n",
    "\n",
    "def test_model(model, test_loader, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    test_results = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels, paths, subjects in tqdm(test_loader, desc='Testing'):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted_indices = torch.max(outputs.data, 1)\n",
    "            predicted_labels = [label_mapping[code] for code in predicted_indices.cpu().numpy()]\n",
    "            for label, pred, path, subject in zip(labels.cpu().numpy(), predicted_labels, paths, subjects):\n",
    "                test_results.append({\n",
    "                    'Subject': subject,\n",
    "                    'Path': path,\n",
    "                    'Actual Label': label_mapping[label.item()],\n",
    "                    'Prediction': pred,\n",
    "                    'Type': 'Test'\n",
    "                })\n",
    "    return test_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = load_datasets(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|          | 0/27 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|          | 0/27 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or no access: 'D:/Data/Preprocessed/Fused Images/032_S_0677_fused.nii'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Micha\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages\\nibabel\\loadsave.py:100\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, **kwargs)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 100\u001b[0m     stat_result \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'D:/Data/Preprocessed/Fused Images/032_S_0677_fused.nii'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Training, Validation, Testing\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m train_results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_epochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m validate_results \u001b[38;5;241m=\u001b[39m validate_model(model, val_loader, criterion, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m     32\u001b[0m test_results \u001b[38;5;241m=\u001b[39m test_model(model, test_loader, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "Cell \u001b[1;32mIn[16], line 6\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, criterion, optimizer, num_epochs, device)\u001b[0m\n\u001b[0;32m      4\u001b[0m train_results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m images, labels, paths, subjects \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      7\u001b[0m         images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      8\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\Micha\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages\\tqdm\\std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Micha\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Micha\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Micha\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Micha\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[8], line 13\u001b[0m, in \u001b[0;36mNiiDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m     12\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpaths[idx]\n\u001b[1;32m---> 13\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mnib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget_fdata()\n\u001b[0;32m     14\u001b[0m     image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(image, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n",
      "File \u001b[1;32mc:\\Users\\Micha\\.pyenv\\pyenv-win\\versions\\3.8.10\\lib\\site-packages\\nibabel\\loadsave.py:102\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, **kwargs)\u001b[0m\n\u001b[0;32m    100\u001b[0m     stat_result \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstat(filename)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m--> 102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or no access: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stat_result\u001b[38;5;241m.\u001b[39mst_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ImageFileError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmpty file: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No such file or no access: 'D:/Data/Preprocessed/Fused Images/032_S_0677_fused.nii'"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "config = {\n",
    "    'num_classes': 3,\n",
    "    'init_filters': 32,\n",
    "    'kernel_size': 3,\n",
    "    'stride': 2,\n",
    "    'num_fc_units': 128,\n",
    "    'optimizer': 'Adam',\n",
    "    'loss_criterion': 'CrossEntropyLoss',\n",
    "    'num_epochs': 10\n",
    "}\n",
    "config_df = pd.DataFrame([config])\n",
    "\n",
    "# Model Initialization\n",
    "model = Baseline3DCNN(num_classes=config['num_classes'],\n",
    "                      init_filters=config['init_filters'],\n",
    "                      kernel_size=config['kernel_size'],\n",
    "                      stride=config['stride'],\n",
    "                      num_fc_units=config['num_fc_units']).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Prepare DataLoaders (assuming your datasets are already split and loaded into variables train_dataset, val_dataset, test_dataset)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "# Training, Validation, Testing\n",
    "train_results = train_model(model, train_loader, criterion, optimizer, num_epochs=config['num_epochs'], device=device)\n",
    "validate_results = validate_model(model, val_loader, criterion, device=device)\n",
    "test_results = test_model(model, test_loader, device=device)\n",
    "\n",
    "# Combine results from all phases\n",
    "all_results = pd.DataFrame(train_results + validate_results + test_results)\n",
    "\n",
    "import datetime\n",
    "\n",
    "# Assuming config_df and all_results are defined elsewhere in your script\n",
    "# Get the current date and time\n",
    "current_time = datetime.datetime.now()\n",
    "formatted_time = current_time.strftime('%Y-%m-%d_%H-%M-%S')  # Format as Year-Month-Day_Hour-Minute-Second\n",
    "\n",
    "# Create a unique filename for each experiment run\n",
    "filename = f'{formatted_time}_Experiment.xlsx'\n",
    "\n",
    "# Export to Excel with a unique filename based on the current date and time\n",
    "with pd.ExcelWriter(filename) as writer:\n",
    "    config_df.to_excel(writer, sheet_name='Configuration')\n",
    "    all_results.to_excel(writer, sheet_name='Results')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping: {0: 'AD', 1: 'CN', 2: 'MCI'}\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is your DataFrame containing the data\n",
    "unique_labels = pd.Categorical(df['Research Group'])\n",
    "label_codes = unique_labels.codes\n",
    "label_names = unique_labels.categories\n",
    "\n",
    "# Create the mapping from codes to names\n",
    "label_mapping = {code: name for code, name in zip(range(len(label_names)), label_names)}\n",
    "print(\"Label Mapping:\", label_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, loader, criterion, phase=\"Validation\"):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    image_paths = []\n",
    "    losses = []\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            probs = softmax(outputs)\n",
    "\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            losses.append(criterion(outputs, labels).item())\n",
    "\n",
    "            # Assuming you have a way to access paths here\n",
    "            image_paths.extend(loader.dataset.paths)\n",
    "\n",
    "    accuracy = 100 * (np.array(predictions) == np.array(true_labels)).sum() / len(predictions)\n",
    "    print(f'{phase} Accuracy: {accuracy}%')\n",
    "\n",
    "    return predictions, true_labels, image_paths, losses, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_metrics(predictions, labels):\n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    # Sensitivity (Recall)\n",
    "    sensitivity = recall_score(labels, predictions, average='macro')  # Adjust average as needed\n",
    "    # Specificity - Calculate from confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(labels, predictions).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"sensitivity\": sensitivity,\n",
    "        \"specificity\": specificity\n",
    "    }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nibabel in c:\\users\\micha\\.pyenv\\pyenv-win\\versions\\3.10.10\\lib\\site-packages (5.2.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\micha\\.pyenv\\pyenv-win\\versions\\3.10.10\\lib\\site-packages (from nibabel) (1.26.4)\n",
      "Requirement already satisfied: packaging>=17 in c:\\users\\micha\\appdata\\roaming\\python\\python310\\site-packages (from nibabel) (23.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nibabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 5.555555555555555%\n",
      "Testing Accuracy: 5.555555555555555%\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m test_predictions, test_labels, test_paths, test_losses, test_accuracy \u001b[38;5;241m=\u001b[39m evaluate_model(model, test_loader, criterion, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Compute metrics\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m val_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m test_metrics \u001b[38;5;241m=\u001b[39m compute_metrics(test_predictions, test_labels)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Log results to a DataFrame and save to Excel\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m, in \u001b[0;36mcompute_metrics\u001b[1;34m(predictions, labels)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_metrics\u001b[39m(predictions, labels):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# Accuracy\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m(labels, predictions)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Sensitivity (Recall)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     sensitivity \u001b[38;5;241m=\u001b[39m recall_score(labels, predictions, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Adjust average as needed\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset, test_dataset = load_datasets(df)\n",
    "train_loader, val_loader, test_loader = create_dataloaders(train_dataset, val_dataset, test_dataset)\n",
    "\n",
    "\n",
    "# Initialize model, loss criterion, and optimizer\n",
    "model = Baseline3DCNN(**params).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Evaluate the model on validation and test sets\n",
    "val_predictions, val_labels, val_paths, val_losses, val_accuracy = evaluate_model(model, val_loader, criterion, \"Validation\")\n",
    "test_predictions, test_labels, test_paths, test_losses, test_accuracy = evaluate_model(model, test_loader, criterion, \"Testing\")\n",
    "\n",
    "# Compute metrics\n",
    "val_metrics = compute_metrics(val_predictions, val_labels)\n",
    "test_metrics = compute_metrics(test_predictions, test_labels)\n",
    "\n",
    "# Log results to a DataFrame and save to Excel\n",
    "results_df = pd.DataFrame({\n",
    "    'Path': val_paths + test_paths,\n",
    "    'True Label': val_labels + test_labels,\n",
    "    'Predicted Label': val_predictions + test_predictions,\n",
    "    'Phase': ['Validation']*len(val_paths) + ['Testing']*len(test_paths),\n",
    "    'Loss': val_losses + test_losses\n",
    "})\n",
    "results_df.to_excel(\"model_results.xlsx\", index=False)\n",
    "\n",
    "# Print metrics for review\n",
    "print(\"Validation Metrics:\", val_metrics)\n",
    "print(\"Test Metrics:\", test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "params = {\n",
    "    'num_classes': 3,\n",
    "    'init_filters': 32,\n",
    "    'kernel_size': 3,\n",
    "    'stride': 2,\n",
    "    'num_fc_units': 128\n",
    "}\n",
    "model = Baseline3DCNN(**params).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_loss = train_model(model, train_loader, criterion, optimizer, num_epochs=10)\n",
    "val_accuracy = validate_model(model, val_loader, criterion)\n",
    "test_accuracy = test_model(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
