{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "# Specify the full path to the module file\n",
    "module_path = 'D:\\\\Github Folder\\\\MasterThesis\\\\Code\\\\FUNCTIONS.py'\n",
    "\n",
    "# Load the module\n",
    "spec = importlib.util.spec_from_file_location(\"FUNCTIONS\", module_path)\n",
    "functions = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(functions)\n",
    "\n",
    "# Now you can use the functions as if you had imported them\n",
    "load_datasets = functions.load_datasets\n",
    "create_dataloaders = functions.create_dataloaders\n",
    "train_and_validate = functions.train_and_validate\n",
    "test_model = functions.test_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r\"references\\NEW_COMBINED_FINAL_Subject_info.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df' is your DataFrame loaded with the 'Research Group' column available\n",
    "label_categories = pd.Categorical(df['Research Group'])\n",
    "label_mapping = {code: category for code, category in enumerate(label_categories.categories)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class VGG3D(nn.Module):\n",
    "    def __init__(self, num_classes=2, input_shape=(1, 193, 229, 193)):\n",
    "        super(VGG3D, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=input_shape[0], out_channels=8, kernel_size=(3,3,3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(in_channels=8, out_channels=8, kernel_size=(3,3,3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=(2,2,2), stride=2)\n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=8, out_channels=16, kernel_size=(3,3,3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(in_channels=16, out_channels=16, kernel_size=(3,3,3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=(2,2,2), stride=2)\n",
    "        )\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=16, out_channels=32, kernel_size=(3,3,3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(in_channels=32, out_channels=32, kernel_size=(3,3,3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(in_channels=32, out_channels=32, kernel_size=(3,3,3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=(2,2,2), stride=2)\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=32, out_channels=64, kernel_size=(3,3,3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(in_channels=64, out_channels=64, kernel_size=(3,3,3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(in_channels=64, out_channels=64, kernel_size=(3,3,3), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool3d(kernel_size=(2,2,2), stride=2)\n",
    "        )\n",
    "        \n",
    "        # This will be updated after running the model to find the correct flattened size\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(129024, 128),  # This number will be updated\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        if(num_classes==2):\n",
    "            self.out = nn.Linear(64, 2)\n",
    "            self.out_act = nn.Sigmoid()\n",
    "        else:\n",
    "            self.out = nn.Linear(64, num_classes)\n",
    "            self.out_act = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x, drop_prob=0.8):\n",
    "        print(\"Input shape:\", x.shape)\n",
    "        x = self.conv1(x)\n",
    "        print(\"After Conv1:\", x.shape)\n",
    "        x = self.conv2(x)\n",
    "        print(\"After Conv2:\", x.shape)\n",
    "        x = self.conv3(x)\n",
    "        print(\"After Conv3:\", x.shape)\n",
    "        x = self.conv4(x)\n",
    "        print(\"After Conv4:\", x.shape)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        print(\"Shape before FC1:\", x.shape)\n",
    "        x = self.fc1(x)\n",
    "        x = nn.Dropout(drop_prob)(x)\n",
    "        x = self.fc2(x)\n",
    "        prob = self.out(x)\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "\n",
    "def run_experiment(df, config):\n",
    "    \"\"\"Run the experiment with the given configuration on the preprocessed DataFrame.\"\"\"\n",
    "    train_dataset, val_dataset, test_dataset = load_datasets(df, config['image_type'])\n",
    "    train_loader, val_loader, test_loader = create_dataloaders(train_dataset, val_dataset, test_dataset, batch_size=config['batch_size'])\n",
    "    \n",
    "    # Initialize model and training components\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = VGG3D().to(device)\n",
    "    \n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    #criterion = nn.BCEWithLogitsLoss()\n",
    "    #optimizer = optim.Adam(model.parameters(), lr=config['lr'])\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'], weight_decay=0.0)\n",
    "       #optimizer = torch.optim.SGD(net.parameters(), lr=LR, momentum=0.9)\n",
    "\n",
    "\n",
    "    # Training and validation\n",
    "    train_accuracies, val_accuracies, val_losses, results_df = train_and_validate(model, train_loader, val_loader, criterion, optimizer, config['num_epochs'], config['patience'], device)\n",
    "    test_results, test_accuracy = test_model(model, test_loader, label_mapping, device)\n",
    "    \n",
    "    # Save detailed results to Excel\n",
    "    current_time = datetime.datetime.now()\n",
    "    formatted_time = current_time.strftime('%Y-%m-%d_%H-%M-%S')\n",
    "    report_filename = os.path.join('reports', f'{formatted_time}_Experiment.xlsx')\n",
    "    onnx_filename = os.path.join('models', f'{formatted_time}_Model.')\n",
    "          # Save the model to ONNX\n",
    "    dummy_input = torch.randn(4, 1, 193, 229, 193, device=device)  # Adjust size according to your model's input\n",
    "    torch.onnx.export(model, dummy_input, onnx_filename, export_params=True)\n",
    "\n",
    "    \n",
    "    summary_data = {\n",
    "        'Phase': ['Training', 'Validation', 'Testing'],\n",
    "        'Accuracy': [train_accuracies[-1], val_accuracies[-1], test_accuracy]\n",
    "    }\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    all_results = pd.DataFrame(test_results)\n",
    "    config_df = pd.DataFrame([config])\n",
    "    \n",
    "    with pd.ExcelWriter(report_filename) as writer:\n",
    "        config_df.to_excel(writer, sheet_name='Configuration')\n",
    "        all_results.to_excel(writer, sheet_name='Results')\n",
    "        summary_df.to_excel(writer, sheet_name='Summary')\n",
    "        results_df.to_excel(writer, sheet_name='Training_Results')\n",
    "\n",
    "# Append a summary of this experiment to the cumulative RESULTS.xlsx file\n",
    "    results_file = os.path.join('reports', 'RESULTS.xlsx')\n",
    "    experiment_summary = {**config, **{'Training Accuracy': train_accuracies[-1], 'Validation Accuracy': val_accuracies[-1], 'Test Accuracy': test_accuracy, 'DATETIME': formatted_time}}\n",
    "    summary_row = pd.DataFrame([experiment_summary])\n",
    "\n",
    "    if os.path.exists(results_file):\n",
    "        with pd.ExcelWriter(results_file, mode='a', engine='openpyxl', if_sheet_exists='overlay') as writer:\n",
    "            existing_df = pd.read_excel(results_file)\n",
    "            combined_df = pd.concat([existing_df, summary_row], ignore_index=True)\n",
    "            combined_df = combined_df.reindex(columns=(existing_df.columns.tolist() + [col for col in summary_row.columns if col not in existing_df.columns]))\n",
    "            combined_df.to_excel(writer, index=False, sheet_name='Sheet1')\n",
    "    else:\n",
    "        summary_row.to_excel(results_file, index=False)\n",
    "\n",
    "    return report_filename, train_accuracies[-1], val_accuracies[-1], test_accuracy\n",
    "\n",
    "\n",
    "# Example configuration and use case\n",
    "config = {\n",
    "    'optimizer': 'Adam',\n",
    "    'lr' : 0.001,\n",
    "    'loss_criterion': 'Cross-Entropy',\n",
    "    'num_epochs': 1,\n",
    "    'batch_size': 2,\n",
    "    'patience': 50,\n",
    "    'Description' : 'VG33D initial test with real dimensions',\n",
    "    'image_type' : 'Fused Images'\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on image type: Fused Images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 - Train:   0%|          | 0/157 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 1, 193, 229, 193])\n",
      "After Conv1: torch.Size([2, 8, 96, 114, 96])\n",
      "After Conv2: torch.Size([2, 16, 48, 57, 48])\n",
      "After Conv3: torch.Size([2, 32, 24, 28, 24])\n",
      "After Conv4: torch.Size([2, 64, 12, 14, 12])\n",
      "Shape before FC1: torch.Size([2, 129024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Micha\\.pyenv\\pyenv-win\\versions\\3.10.10\\lib\\site-packages\\torch\\autograd\\graph.py:744: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 1.02 GiB. GPU  (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:924.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "c:\\Users\\Micha\\.pyenv\\pyenv-win\\versions\\3.10.10\\lib\\site-packages\\torch\\autograd\\graph.py:744: UserWarning: Plan failed with an OutOfMemoryError: CUDA out of memory. Tried to allocate 1.03 GiB. GPU  (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:924.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "Epoch 1/1 - Train:   1%|          | 1/157 [00:09<23:28,  9.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 1, 193, 229, 193])\n",
      "After Conv1: torch.Size([2, 8, 96, 114, 96])\n",
      "After Conv2: torch.Size([2, 16, 48, 57, 48])\n",
      "After Conv3: torch.Size([2, 32, 24, 28, 24])\n",
      "After Conv4: torch.Size([2, 64, 12, 14, 12])\n",
      "Shape before FC1: torch.Size([2, 129024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 - Train:   1%|          | 1/157 [00:15<41:11, 15.84s/it]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 522.00 MiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m image_type\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWorking on image type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m results\u001b[38;5;241m.\u001b[39mappend(result)\n",
      "Cell \u001b[1;32mIn[21], line 29\u001b[0m, in \u001b[0;36mrun_experiment\u001b[1;34m(df, config)\u001b[0m\n\u001b[0;32m     24\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m], weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m)\n\u001b[0;32m     25\u001b[0m    \u001b[38;5;66;03m#optimizer = torch.optim.SGD(net.parameters(), lr=LR, momentum=0.9)\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \n\u001b[0;32m     27\u001b[0m \n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Training and validation\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m train_accuracies, val_accuracies, val_losses, results_df \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_epochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpatience\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m test_results, test_accuracy \u001b[38;5;241m=\u001b[39m test_model(model, test_loader, label_mapping, device)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Save detailed results to Excel\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Github Folder\\MasterThesis\\Code\\FUNCTIONS.py:157\u001b[0m, in \u001b[0;36mtrain_and_validate\u001b[1;34m(model, train_loader, val_loader, criterion, optimizer, num_epochs, patience, device)\u001b[0m\n\u001b[0;32m    155\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[0;32m    156\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m--> 157\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    159\u001b[0m train_epoch_losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[1;32mc:\\Users\\Micha\\.pyenv\\pyenv-win\\versions\\3.10.10\\lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Micha\\.pyenv\\pyenv-win\\versions\\3.10.10\\lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Micha\\.pyenv\\pyenv-win\\versions\\3.10.10\\lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    745\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    746\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 522.00 MiB. GPU "
     ]
    }
   ],
   "source": [
    "  #column_mapping = {\n",
    "  #          'Co-registered PET': 'Co-registered PET',\n",
    "   #         'Fused Images': 'Fused Images',\n",
    "    #        'Masked PET': 'Masked PET',\n",
    "     #       'Spatial Normalization': 'Spatial Normalization',\n",
    "      #      'Resampled Images(Co-registered PET)': 'Resampled Images(Co-registered PET)',\n",
    "       #     'Resampled Images(Masked PET)': 'Resampled Images(Masked PET)',\n",
    "        #    'Resampled Images(Spatial Normalization)': 'Resampled Images(Spatial Normalization)',\n",
    "         #   'Resampled Images_fused': 'Resampled Images_fused'\n",
    "        #}\n",
    "\n",
    "image_types = ['Fused Images']\n",
    "results = []\n",
    "for image_type in image_types:\n",
    "    config['image_type'] = image_type\n",
    "    print(f\"Working on image type: {image_type}\")\n",
    "    result = run_experiment(df, config)\n",
    "    results.append(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
