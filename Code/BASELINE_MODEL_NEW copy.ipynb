{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "# Specify the full path to the module file\n",
    "module_path = 'D:\\\\Github Folder\\\\MasterThesis\\\\notebooks\\\\FUNCTIONS.py'\n",
    "\n",
    "# Load the module\n",
    "spec = importlib.util.spec_from_file_location(\"FUNCTIONS\", module_path)\n",
    "functions = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(functions)\n",
    "\n",
    "# Now you can use the functions as if you had imported them\n",
    "load_datasets = functions.load_datasets\n",
    "create_dataloaders = functions.create_dataloaders\n",
    "train_and_validate = functions.train_and_validate\n",
    "test_model = functions.test_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"references\\Subject_info_balanced.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'df' is your DataFrame loaded with the 'Research Group' column available\n",
    "label_categories = pd.Categorical(df['Research Group'])\n",
    "label_mapping = {code: category for code, category in enumerate(label_categories.categories)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline3DCNN(nn.Module):\n",
    "    def __init__(self, num_classes=2, init_filters=8, kernel_size=2, stride=2, num_fc_units=128):\n",
    "        super(Baseline3DCNN, self).__init__()\n",
    "        self.init_filters = init_filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.num_fc_units = num_fc_units\n",
    "\n",
    "        self.conv1 = nn.Conv3d(1, init_filters, kernel_size=kernel_size, stride=stride, padding=kernel_size//2)\n",
    "        self.conv2 = nn.Conv3d(init_filters, init_filters*2, kernel_size=kernel_size, stride=stride, padding=kernel_size//2)\n",
    "        self.conv3 = nn.Conv3d(init_filters*2, init_filters*4, kernel_size=kernel_size, stride=stride, padding=kernel_size//2)\n",
    "        self.pool = nn.MaxPool3d(2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Example input to determine the size\n",
    "        example_input = torch.randn(1, 1, 193, 229, 193)\n",
    "        example_output = self.forward_features(example_input)\n",
    "        self.final_dim = example_output.numel()\n",
    "\n",
    "        self.fc1 = nn.Linear(self.final_dim, num_fc_units)\n",
    "        self.fc2 = nn.Linear(num_fc_units, num_classes)\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.pool(self.relu(self.conv3(x)))\n",
    "        return torch.flatten(x, start_dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Assuming Baseline3DCNN, train_and_validate, test_model, and related utilities are defined elsewhere\n",
    "\n",
    "def run_experiment(df, config):\n",
    "    \"\"\"Run the experiment with the given configuration on the preprocessed DataFrame.\"\"\"\n",
    "    train_dataset, val_dataset, test_dataset = load_datasets(df, config['image_type'], sample_size=config['sample_size'])\n",
    "    train_loader, val_loader, test_loader = create_dataloaders(train_dataset, val_dataset, test_dataset, batch_size=config['batch_size'])\n",
    "    \n",
    "    # Initialize model and training components\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = Baseline3DCNN(num_classes=config['num_classes'], init_filters=config['init_filters'],\n",
    "                          kernel_size=config['kernel_size'], stride=config['stride'], num_fc_units=config['num_fc_units']).to(device)\n",
    "    \n",
    "\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "    # Training and validation\n",
    "    train_accuracies, val_accuracies, val_losses = train_and_validate(model, train_loader, val_loader, criterion, optimizer, label_mapping, config['num_epochs'], config['patience'], device)\n",
    "    test_results, test_accuracy = test_model(model, test_loader, label_mapping, device)\n",
    "    \n",
    "    # Save detailed results to Excel\n",
    "    current_time = datetime.datetime.now()\n",
    "    formatted_time = current_time.strftime('%Y-%m-%d_%H-%M-%S')\n",
    "    report_filename = os.path.join('reports', f'{formatted_time}_Experiment.xlsx')\n",
    "    onnx_filename = os.path.join('models', f'{formatted_time}_Model.onnx')\n",
    "    \n",
    "    summary_data = {\n",
    "        'Phase': ['Training', 'Validation', 'Testing'],\n",
    "        'Accuracy': [train_accuracies[-1], val_accuracies[-1], test_accuracy]\n",
    "    }\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    all_results = pd.DataFrame(test_results)\n",
    "    config_df = pd.DataFrame([config])\n",
    "    \n",
    "    with pd.ExcelWriter(report_filename) as writer:\n",
    "        config_df.to_excel(writer, sheet_name='Configuration')\n",
    "        all_results.to_excel(writer, sheet_name='Results')\n",
    "        summary_df.to_excel(writer, sheet_name='Summary')\n",
    "\n",
    "    # Append a summary of this experiment to the cumulative RESULTS.xlsx file\n",
    "    results_file = os.path.join('reports', 'RESULTS.xlsx')\n",
    "    experiment_summary = {**config, **{'Training Accuracy': train_accuracies[-1], 'Validation Accuracy': val_accuracies[-1], 'Test Accuracy': test_accuracy, 'DATETIME': formatted_time}}\n",
    "    summary_row = pd.DataFrame([experiment_summary])\n",
    "\n",
    "    if os.path.exists(results_file):\n",
    "        with pd.ExcelWriter(results_file, mode='a', engine='openpyxl', if_sheet_exists='overlay') as writer:\n",
    "            existing_df = pd.read_excel(results_file)\n",
    "            combined_df = pd.concat([existing_df, summary_row], ignore_index=True)\n",
    "            combined_df = combined_df.reindex(columns=(existing_df.columns.tolist() + [col for col in summary_row.columns if col not in existing_df.columns]))\n",
    "            combined_df.to_excel(writer, index=False, sheet_name='Sheet1')\n",
    "    else:\n",
    "        summary_row.to_excel(results_file, index=False)\n",
    "\n",
    "    # Save the model to ONNX\n",
    "    dummy_input = torch.randn(1, 1, 193, 229, 193, device=device)  # Adjust size according to your model's input\n",
    "    torch.onnx.export(model, dummy_input, onnx_filename, export_params=True)\n",
    "\n",
    "    return report_filename, train_accuracies[-1], val_accuracies[-1], test_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on image type: PET\n",
      "Running experiment with init_filters=256, kernel_size=2, batch_size=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60 - Train: 100%|██████████| 19/19 [03:37<00:00, 11.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 3.5890 - Train Accuracy: 50.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/60 - Validate: 100%|██████████| 6/6 [00:20<00:00,  3.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Validation Loss: 0.6892 - Validation Accuracy: 50.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/60 - Train: 100%|██████████| 19/19 [03:40<00:00, 11.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 0.6933 - Train Accuracy: 50.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/60 - Validate: 100%|██████████| 6/6 [00:18<00:00,  3.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Validation Loss: 0.6935 - Validation Accuracy: 50.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/60 - Train: 100%|██████████| 19/19 [03:33<00:00, 11.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.6946 - Train Accuracy: 48.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/60 - Validate: 100%|██████████| 6/6 [00:18<00:00,  3.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Validation Loss: 0.6935 - Validation Accuracy: 50.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/60 - Train: 100%|██████████| 19/19 [03:32<00:00, 11.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 0.6985 - Train Accuracy: 46.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/60 - Validate: 100%|██████████| 6/6 [00:18<00:00,  3.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Validation Loss: 0.6932 - Validation Accuracy: 54.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/60 - Train: 100%|██████████| 19/19 [03:33<00:00, 11.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 0.6931 - Train Accuracy: 51.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/60 - Validate: 100%|██████████| 6/6 [00:19<00:00,  3.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Validation Loss: 0.6949 - Validation Accuracy: 50.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/60 - Train: 100%|██████████| 19/19 [03:33<00:00, 11.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss: 0.6931 - Train Accuracy: 50.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/60 - Validate: 100%|██████████| 6/6 [00:18<00:00,  3.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Validation Loss: 0.6952 - Validation Accuracy: 45.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/60 - Train: 100%|██████████| 19/19 [03:32<00:00, 11.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss: 0.6916 - Train Accuracy: 51.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/60 - Validate: 100%|██████████| 6/6 [00:18<00:00,  3.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Validation Loss: 0.7015 - Validation Accuracy: 41.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/60 - Train: 100%|██████████| 19/19 [03:34<00:00, 11.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss: 0.7284 - Train Accuracy: 59.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/60 - Validate: 100%|██████████| 6/6 [00:19<00:00,  3.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Validation Loss: 0.6952 - Validation Accuracy: 50.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/60 - Train: 100%|██████████| 19/19 [03:33<00:00, 11.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss: 0.7011 - Train Accuracy: 50.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/60 - Validate: 100%|██████████| 6/6 [00:18<00:00,  3.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Validation Loss: 0.6940 - Validation Accuracy: 45.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/60 - Train: 100%|██████████| 19/19 [03:34<00:00, 11.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss: 0.6949 - Train Accuracy: 42.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/60 - Validate: 100%|██████████| 6/6 [00:18<00:00,  3.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Validation Loss: 0.6940 - Validation Accuracy: 50.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/60 - Train: 100%|██████████| 19/19 [03:33<00:00, 11.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss: 0.6937 - Train Accuracy: 52.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/60 - Validate: 100%|██████████| 6/6 [00:19<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Validation Loss: 0.6944 - Validation Accuracy: 50.00%\n",
      "Early stopping triggered after 11 epochs due to no improvement in validation loss or accuracy.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 6/6 [00:20<00:00,  3.44s/it]\n",
      "C:\\Users\\Micha\\AppData\\Local\\Temp\\ipykernel_50712\\3617251816.py:57: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([existing_df, summary_row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiments completed. Results collected.\n"
     ]
    }
   ],
   "source": [
    "image_types = ['PET']\n",
    "init_filters_options = [256]\n",
    "kernel_size_options = [2]\n",
    "batch_size_options = [4]\n",
    "\n",
    "# Base configuration for experiments\n",
    "base_config = {\n",
    "    'num_classes': 2,\n",
    "    'stride': 2,\n",
    "    'num_fc_units': 128,\n",
    "    'optimizer': 'Adam',\n",
    "    'loss_criterion': 'CrossEntropyLoss',\n",
    "    'num_epochs': 60,\n",
    "    'patience': 10,\n",
    "    'Description': 'Baseline3DCNN - Simple model architecture',\n",
    "    'sample_size': None\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "# Outermost loop for image types\n",
    "for image_type in image_types:\n",
    "    # Update the image type in the configuration\n",
    "    config = base_config.copy()\n",
    "    config['image_type'] = image_type\n",
    "    \n",
    "    print(f\"Working on image type: {image_type}\")\n",
    "    \n",
    "    # Loop for init_filters\n",
    "    for init_filter in init_filters_options:\n",
    "        config['init_filters'] = init_filter\n",
    "        \n",
    "        # Loop for kernel_size\n",
    "        for kernel_size in kernel_size_options:\n",
    "            config['kernel_size'] = kernel_size\n",
    "            \n",
    "            # Loop for batch_size\n",
    "            for batch_size in batch_size_options:\n",
    "                config['batch_size'] = batch_size\n",
    "                \n",
    "                # Log the current configuration\n",
    "                print(f\"Running experiment with init_filters={init_filter}, kernel_size={kernel_size}, batch_size={batch_size}\")\n",
    "                \n",
    "                # Run the experiment and store the result\n",
    "                result = run_experiment(df, config)\n",
    "                results.append((config.copy(), result))\n",
    "\n",
    "# Print or process results as needed\n",
    "print(\"Experiments completed. Results collected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
