{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 20, 20, 20])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "# Create a 3D convolutional layer\n",
    "# in_channels = 1, out_channels = 32, kernel_size = 3, stride = 1, padding = 1\n",
    "conv_layer = nn.Conv3d(1, 32, 3, stride=1, padding=1)\n",
    "\n",
    "# Example input tensor: (batch_size, channels, depth, height, width)\n",
    "# For a single sample with 1 channel and 20x20x20 size\n",
    "input_tensor = torch.randn(1, 1, 20, 20, 20)\n",
    "\n",
    "# Apply the convolutional layer to the input\n",
    "output_tensor = conv_layer(input_tensor)\n",
    "\n",
    "print(output_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(193, 229, 193)\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "\n",
    "# Load the NIfTI file\n",
    "nifti_file = nib.load(r'data\\first_fusion\\002_S_0295_fused.nii')\n",
    "\n",
    "# Get the data from the file\n",
    "data = nifti_file.get_fdata()\n",
    "print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affine matrix:\n",
      "[[   1.    0.    0.  -96.]\n",
      " [   0.    1.    0. -132.]\n",
      " [   0.    0.    1.  -74.]\n",
      " [   0.    0.    0.    1.]]\n",
      "Header data:\n",
      "<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\n",
      "sizeof_hdr      : 348\n",
      "data_type       : b''\n",
      "db_name         : b''\n",
      "extents         : 0\n",
      "session_error   : 0\n",
      "regular         : b''\n",
      "dim_info        : 0\n",
      "dim             : [  3 193 229 193   1   1   1   1]\n",
      "intent_p1       : 0.0\n",
      "intent_p2       : 0.0\n",
      "intent_p3       : 0.0\n",
      "intent_code     : none\n",
      "datatype        : float64\n",
      "bitpix          : 64\n",
      "slice_start     : 0\n",
      "pixdim          : [1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "vox_offset      : 0.0\n",
      "scl_slope       : nan\n",
      "scl_inter       : nan\n",
      "slice_end       : 0\n",
      "slice_code      : unknown\n",
      "xyzt_units      : 0\n",
      "cal_max         : 0.0\n",
      "cal_min         : 0.0\n",
      "slice_duration  : 0.0\n",
      "toffset         : 0.0\n",
      "glmax           : 0\n",
      "glmin           : 0\n",
      "descrip         : b''\n",
      "aux_file        : b''\n",
      "qform_code      : unknown\n",
      "sform_code      : aligned\n",
      "quatern_b       : 0.0\n",
      "quatern_c       : 0.0\n",
      "quatern_d       : 0.0\n",
      "qoffset_x       : -96.0\n",
      "qoffset_y       : -132.0\n",
      "qoffset_z       : -74.0\n",
      "srow_x          : [  1.   0.   0. -96.]\n",
      "srow_y          : [   0.    1.    0. -132.]\n",
      "srow_z          : [  0.   0.   1. -74.]\n",
      "intent_name     : b''\n",
      "magic           : b'n+1'\n"
     ]
    }
   ],
   "source": [
    "# Print the affine matrix\n",
    "print(\"Affine matrix:\")\n",
    "print(nifti_file.affine)\n",
    "\n",
    "# Header might also contain useful orientation and dimension info\n",
    "print(\"Header data:\")\n",
    "print(nifti_file.header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape after first layer: torch.Size([1, 32, 132, 168, 132])\n",
      "Output shape after second layer: torch.Size([1, 64, 66, 84, 66])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the input tensor for a single grayscale 3D image\n",
    "input_tensor = torch.randn(1, 1, 193, 229, 193)  # (batch_size, channels, depth, height, width)\n",
    "\n",
    "# First convolutional layer\n",
    "conv_layer1 = nn.Conv3d(in_channels=1, out_channels=32, kernel_size=64, stride=1, padding=1)\n",
    "output1 = conv_layer1(input_tensor)\n",
    "print(\"Output shape after first layer:\", output1.shape)\n",
    "\n",
    "# Second convolutional layer\n",
    "conv_layer2 = nn.Conv3d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1)\n",
    "output2 = conv_layer2(output1)\n",
    "print(\"Output shape after second layer:\", output2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN3D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN3D, self).__init__()\n",
    "        # Define the convolutional layers and pooling layer\n",
    "        self.conv1 = nn.Conv3d(in_channels=1, out_channels=16, kernel_size=16, stride=4, padding=0)\n",
    "        self.pool = nn.MaxPool3d(kernel_size=1)\n",
    "        self.conv2 = nn.Conv3d(in_channels=16, out_channels=32, kernel_size=8, stride=2, padding=0)\n",
    "        self.conv3 = nn.Conv3d(in_channels=32, out_channels=64, kernel_size=4, stride=2, padding=0)\n",
    "        self.conv4 = nn.Conv3d(in_channels=64, out_channels=128, kernel_size=2, stride=2, padding=0)\n",
    "        # Assuming some volume remains here for the sake of example, often requires actual calculation\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(in_features=128 * 128, out_features=1024)  # Placeholder for in_features\n",
    "        self.fc2 = nn.Linear(in_features=1024, out_features=128)\n",
    "        self.fc3 = nn.Linear(in_features=128, out_features=32)\n",
    "        self.output = nn.Linear(in_features=32, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        print(\"After Conv1:\", x.shape)\n",
    "        x = self.pool(x)\n",
    "        print(\"After Pool1:\", x.shape)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        print(\"After Conv2:\", x.shape)\n",
    "        x = self.pool(x)\n",
    "        print(\"After Pool2:\", x.shape)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        print(\"After Conv3:\", x.shape)\n",
    "        x = self.pool(x)\n",
    "        print(\"After Pool3:\", x.shape)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        print(\"After Conv4:\", x.shape)\n",
    "        x = self.pool(x)\n",
    "        print(\"After Pool4:\", x.shape)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        print(\"After Flatten:\", x.shape)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        print(\"After FC1:\", x.shape)\n",
    "        \n",
    "        x = F.relu(self.fc2(x))\n",
    "        print(\"After FC2:\", x.shape)\n",
    "        \n",
    "        x = F.relu(self.fc3(x))\n",
    "        print(\"After FC3:\", x.shape)\n",
    "        \n",
    "        x = torch.sigmoid(self.output(x))\n",
    "        print(\"After Sigmoid:\", x.shape)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Conv1: torch.Size([1, 16, 45, 54, 45])\n",
      "After Pool1: torch.Size([1, 16, 45, 54, 45])\n",
      "After Conv2: torch.Size([1, 32, 19, 24, 19])\n",
      "After Pool2: torch.Size([1, 32, 19, 24, 19])\n",
      "After Conv3: torch.Size([1, 64, 8, 11, 8])\n",
      "After Pool3: torch.Size([1, 64, 8, 11, 8])\n",
      "After Conv4: torch.Size([1, 128, 4, 5, 4])\n",
      "After Pool4: torch.Size([1, 128, 4, 5, 4])\n",
      "After Flatten: torch.Size([1, 10240])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x10240 and 16384x1024)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m input_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m193\u001b[39m, \u001b[38;5;241m229\u001b[39m, \u001b[38;5;241m193\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Pass the tensor through the model\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Micha\\.pyenv\\pyenv-win\\versions\\3.10.10\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Micha\\.pyenv\\pyenv-win\\versions\\3.10.10\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[23], line 45\u001b[0m, in \u001b[0;36mCNN3D.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     42\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten(x)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAfter Flatten:\u001b[39m\u001b[38;5;124m\"\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 45\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAfter FC1:\u001b[39m\u001b[38;5;124m\"\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     48\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x))\n",
      "File \u001b[1;32mc:\\Users\\Micha\\.pyenv\\pyenv-win\\versions\\3.10.10\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Micha\\.pyenv\\pyenv-win\\versions\\3.10.10\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Micha\\.pyenv\\pyenv-win\\versions\\3.10.10\\lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x10240 and 16384x1024)"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create the model\n",
    "model = CNN3D()\n",
    "\n",
    "# Initialize a tensor to match the input size described\n",
    "input_tensor = torch.randn(1, 1, 193, 229, 193)\n",
    "\n",
    "# Pass the tensor through the model\n",
    "output = model(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
